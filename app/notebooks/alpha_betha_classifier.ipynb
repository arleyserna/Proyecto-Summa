{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-4429eBoMq0y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/dataset_alpha_betha.csv') #Por favor ajustar la ruta del archivo al valor correspondiente dónde se ubique el archivo."
      ],
      "metadata": {
        "id": "Ugl_pCY-M-Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Demand'] = pd.to_numeric(df['Demand'], errors='coerce')\n",
        "df['Charges'] = pd.to_numeric(df['Charges'], errors='coerce')\n",
        "df.isnull().sum()\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "cuSTZw9NPl7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Class', 'autoID'], axis=1)  # AutoID no es útil para predicción\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "sMwB1c1lNokc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le_target = LabelEncoder()\n",
        "y_encoded = le_target.fit_transform(y)\n",
        "numeric_features = ['Charges', 'Demand']\n",
        "categorical_features = [col for col in X.columns if col not in numeric_features]\n"
      ],
      "metadata": {
        "id": "DjkqyJ_9Nu4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploramos y codificamos el dataset para las variables categóricas\n",
        "\n",
        "X_encoded = X.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "    print(f\"   {col}: {len(le.classes_)} categorías únicas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CIEhIekN8yb",
        "outputId": "44814c2f-41da-4bb1-8e3c-507d0be7a80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SeniorCity: 2 categorías únicas\n",
            "   Partner: 2 categorías únicas\n",
            "   Dependents: 2 categorías únicas\n",
            "   Service1: 2 categorías únicas\n",
            "   Service2: 3 categorías únicas\n",
            "   Security: 3 categorías únicas\n",
            "   OnlineBackup: 3 categorías únicas\n",
            "   DeviceProtection: 3 categorías únicas\n",
            "   TechSupport: 3 categorías únicas\n",
            "   Contract: 3 categorías únicas\n",
            "   PaperlessBilling: 2 categorías únicas\n",
            "   PaymentMethod: 4 categorías únicas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = pd.get_dummies(X_encoded, columns=categorical_features, drop_first=True)"
      ],
      "metadata": {
        "id": "C6TfiaF2jyuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisamos como nos quedó el dataset nuevo.\n",
        "\n",
        "X_encoded.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z8kEa2KiSau",
        "outputId": "4ec08f00-e4be-412b-fe9d-81656d5ca671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7032 entries, 0 to 7042\n",
            "Data columns (total 22 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Charges             7032 non-null   float64\n",
            " 1   Demand              7032 non-null   float64\n",
            " 2   SeniorCity_1        7032 non-null   bool   \n",
            " 3   Partner_1           7032 non-null   bool   \n",
            " 4   Dependents_1        7032 non-null   bool   \n",
            " 5   Service1_1          7032 non-null   bool   \n",
            " 6   Service2_1          7032 non-null   bool   \n",
            " 7   Service2_2          7032 non-null   bool   \n",
            " 8   Security_1          7032 non-null   bool   \n",
            " 9   Security_2          7032 non-null   bool   \n",
            " 10  OnlineBackup_1      7032 non-null   bool   \n",
            " 11  OnlineBackup_2      7032 non-null   bool   \n",
            " 12  DeviceProtection_1  7032 non-null   bool   \n",
            " 13  DeviceProtection_2  7032 non-null   bool   \n",
            " 14  TechSupport_1       7032 non-null   bool   \n",
            " 15  TechSupport_2       7032 non-null   bool   \n",
            " 16  Contract_1          7032 non-null   bool   \n",
            " 17  Contract_2          7032 non-null   bool   \n",
            " 18  PaperlessBilling_1  7032 non-null   bool   \n",
            " 19  PaymentMethod_1     7032 non-null   bool   \n",
            " 20  PaymentMethod_2     7032 non-null   bool   \n",
            " 21  PaymentMethod_3     7032 non-null   bool   \n",
            "dtypes: bool(20), float64(2)\n",
            "memory usage: 302.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Partimos los datos en entrenamiento y prueba.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded,\n",
        "    y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded  # Mantiene proporciones de clases\n",
        ")"
      ],
      "metadata": {
        "id": "joLA2UvpOAvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado el desbalance entre las clase Alpha y Betha, hacemos un oversampling sobre el conjunto de entrenamiento para escalar los datos de Betha.\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "jNvGBlH_QSis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos un conjunto de modelos de base para explorar en un primer nivel como se comportan los datos según estos.\n",
        "\n",
        "models = {\n",
        "    'SVM': svm.SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression()\n",
        "}"
      ],
      "metadata": {
        "id": "vWiLVBYOWq8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Trainer nos permite probar múltiples modelos usando un pipeline.\n",
        "\n",
        "class ModelTrainer:\n",
        "\n",
        "  def __init__(self, models, X_train, y_train, X_test, y_test, components):\n",
        "    self.models = models\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "    self.components = components\n",
        "\n",
        "  def train_models(self):\n",
        "\n",
        "    for name, model in self.models.items():\n",
        "\n",
        "      pipeline = make_pipeline(\n",
        "        #StandardScaler(),\n",
        "        PCA(n_components=self.components),\n",
        "        model\n",
        "      )\n",
        "\n",
        "      pipeline.fit(self.X_train, self.y_train)\n",
        "\n",
        "      y_pred = pipeline.predict(self.X_test)\n",
        "\n",
        "      print(f'Modelo: {name}')\n",
        "      print(f'Precisión: {accuracy_score(self.y_test, y_pred)}')\n",
        "      print(classification_report(self.y_test, y_pred))\n",
        "      print(confusion_matrix(self.y_test, y_pred))\n",
        "      print('-' * 50)\n"
      ],
      "metadata": {
        "id": "jyzf87zUXQUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelTrainer(models, X_train, y_train, X_test, y_test, 2).train_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUFd4FkPZQRO",
        "outputId": "14810de8-b7b4-4ce6-edd1-5f67da34d895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo: SVM\n",
            "Precisión: 0.7341862117981521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1033\n",
            "           1       0.00      0.00      0.00       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.37      0.50      0.42      1407\n",
            "weighted avg       0.54      0.73      0.62      1407\n",
            "\n",
            "[[1033    0]\n",
            " [ 374    0]]\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Precisión: 0.7114427860696517\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.80      1033\n",
            "           1       0.46      0.44      0.45       374\n",
            "\n",
            "    accuracy                           0.71      1407\n",
            "   macro avg       0.63      0.63      0.63      1407\n",
            "weighted avg       0.71      0.71      0.71      1407\n",
            "\n",
            "[[836 197]\n",
            " [209 165]]\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Precisión: 0.7583511016346838\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84      1033\n",
            "           1       0.55      0.46      0.50       374\n",
            "\n",
            "    accuracy                           0.76      1407\n",
            "   macro avg       0.69      0.66      0.67      1407\n",
            "weighted avg       0.75      0.76      0.75      1407\n",
            "\n",
            "[[894 139]\n",
            " [201 173]]\n",
            "--------------------------------------------------\n",
            "Modelo: KNN\n",
            "Precisión: 0.7555081734186212\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1033\n",
            "           1       0.55      0.44      0.49       374\n",
            "\n",
            "    accuracy                           0.76      1407\n",
            "   macro avg       0.68      0.65      0.66      1407\n",
            "weighted avg       0.74      0.76      0.75      1407\n",
            "\n",
            "[[900 133]\n",
            " [211 163]]\n",
            "--------------------------------------------------\n",
            "Modelo: Logistic Regression\n",
            "Precisión: 0.7775408670931059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86      1033\n",
            "           1       0.61      0.44      0.51       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.67      0.68      1407\n",
            "weighted avg       0.76      0.78      0.76      1407\n",
            "\n",
            "[[929 104]\n",
            " [209 165]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de los modelos anteriores no son muy precisos ni exhaustivos sobre todo para la clase Betha, cuyo desbalance es la 4ta parte de la clase Alpha."
      ],
      "metadata": {
        "id": "MexqHS9TxoA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Repetimos el mismo procedimiento haciendo análisis de componentes.\n",
        "\n",
        "components = [3, 5, 7, 12]\n",
        "\n",
        "for comp in components:\n",
        "  print(f'Componentes: {comp}')\n",
        "  ModelTrainer(models, X_train, y_train, X_test, y_test, comp).train_models()\n",
        "  print('-' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgcCvAFOZvi6",
        "outputId": "43949224-6d14-4ff7-bb74-fe4e510f9a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Componentes: 3\n",
            "Modelo: SVM\n",
            "Precisión: 0.7341862117981521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1033\n",
            "           1       0.00      0.00      0.00       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.37      0.50      0.42      1407\n",
            "weighted avg       0.54      0.73      0.62      1407\n",
            "\n",
            "[[1033    0]\n",
            " [ 374    0]]\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Precisión: 0.7157071783937455\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81      1033\n",
            "           1       0.47      0.47      0.47       374\n",
            "\n",
            "    accuracy                           0.72      1407\n",
            "   macro avg       0.64      0.64      0.64      1407\n",
            "weighted avg       0.72      0.72      0.72      1407\n",
            "\n",
            "[[833 200]\n",
            " [200 174]]\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Precisión: 0.7690120824449183\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.85      1033\n",
            "           1       0.58      0.49      0.53       374\n",
            "\n",
            "    accuracy                           0.77      1407\n",
            "   macro avg       0.70      0.68      0.69      1407\n",
            "weighted avg       0.76      0.77      0.76      1407\n",
            "\n",
            "[[900 133]\n",
            " [192 182]]\n",
            "--------------------------------------------------\n",
            "Modelo: KNN\n",
            "Precisión: 0.757640369580668\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1033\n",
            "           1       0.56      0.44      0.49       374\n",
            "\n",
            "    accuracy                           0.76      1407\n",
            "   macro avg       0.68      0.65      0.66      1407\n",
            "weighted avg       0.74      0.76      0.75      1407\n",
            "\n",
            "[[903 130]\n",
            " [211 163]]\n",
            "--------------------------------------------------\n",
            "Modelo: Logistic Regression\n",
            "Precisión: 0.7775408670931059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86      1033\n",
            "           1       0.61      0.44      0.51       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.67      0.68      1407\n",
            "weighted avg       0.76      0.78      0.76      1407\n",
            "\n",
            "[[929 104]\n",
            " [209 165]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Componentes: 5\n",
            "Modelo: SVM\n",
            "Precisión: 0.7341862117981521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1033\n",
            "           1       0.00      0.00      0.00       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.37      0.50      0.42      1407\n",
            "weighted avg       0.54      0.73      0.62      1407\n",
            "\n",
            "[[1033    0]\n",
            " [ 374    0]]\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Precisión: 0.7292110874200426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.82      1033\n",
            "           1       0.49      0.47      0.48       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.65      0.65      0.65      1407\n",
            "weighted avg       0.73      0.73      0.73      1407\n",
            "\n",
            "[[851 182]\n",
            " [199 175]]\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Precisión: 0.7874911158493249\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1033\n",
            "           1       0.62      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "[[919 114]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "Modelo: KNN\n",
            "Precisión: 0.7526652452025586\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1033\n",
            "           1       0.54      0.43      0.48       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.68      0.65      0.66      1407\n",
            "weighted avg       0.74      0.75      0.74      1407\n",
            "\n",
            "[[900 133]\n",
            " [215 159]]\n",
            "--------------------------------------------------\n",
            "Modelo: Logistic Regression\n",
            "Precisión: 0.7917555081734187\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86      1033\n",
            "           1       0.64      0.49      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.74      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "[[930 103]\n",
            " [190 184]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Componentes: 7\n",
            "Modelo: SVM\n",
            "Precisión: 0.7341862117981521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1033\n",
            "           1       0.00      0.00      0.00       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.37      0.50      0.42      1407\n",
            "weighted avg       0.54      0.73      0.62      1407\n",
            "\n",
            "[[1033    0]\n",
            " [ 374    0]]\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Precisión: 0.7348969438521677\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      1033\n",
            "           1       0.50      0.51      0.50       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.66      0.66      0.66      1407\n",
            "weighted avg       0.74      0.73      0.74      1407\n",
            "\n",
            "[[845 188]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Precisión: 0.7746979388770433\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85      1033\n",
            "           1       0.59      0.48      0.53       374\n",
            "\n",
            "    accuracy                           0.77      1407\n",
            "   macro avg       0.71      0.68      0.69      1407\n",
            "weighted avg       0.76      0.77      0.77      1407\n",
            "\n",
            "[[911 122]\n",
            " [195 179]]\n",
            "--------------------------------------------------\n",
            "Modelo: KNN\n",
            "Precisión: 0.7505330490405118\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1033\n",
            "           1       0.54      0.43      0.48       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.67      0.65      0.66      1407\n",
            "weighted avg       0.74      0.75      0.74      1407\n",
            "\n",
            "[[896 137]\n",
            " [214 160]]\n",
            "--------------------------------------------------\n",
            "Modelo: Logistic Regression\n",
            "Precisión: 0.7903340440653873\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86      1033\n",
            "           1       0.64      0.49      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "[[927 106]\n",
            " [189 185]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Componentes: 12\n",
            "Modelo: SVM\n",
            "Precisión: 0.7341862117981521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1033\n",
            "           1       0.00      0.00      0.00       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.37      0.50      0.42      1407\n",
            "weighted avg       0.54      0.73      0.62      1407\n",
            "\n",
            "[[1033    0]\n",
            " [ 374    0]]\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Precisión: 0.7270788912579957\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      1033\n",
            "           1       0.49      0.52      0.50       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.65      0.66      0.66      1407\n",
            "weighted avg       0.73      0.73      0.73      1407\n",
            "\n",
            "[[829 204]\n",
            " [180 194]]\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Precisión: 0.775408670931059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      1033\n",
            "           1       0.60      0.48      0.53       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.68      0.69      1407\n",
            "weighted avg       0.76      0.78      0.77      1407\n",
            "\n",
            "[[910 123]\n",
            " [193 181]]\n",
            "--------------------------------------------------\n",
            "Modelo: KNN\n",
            "Precisión: 0.7526652452025586\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84      1033\n",
            "           1       0.54      0.43      0.48       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.68      0.65      0.66      1407\n",
            "weighted avg       0.74      0.75      0.74      1407\n",
            "\n",
            "[[900 133]\n",
            " [215 159]]\n",
            "--------------------------------------------------\n",
            "Modelo: Logistic Regression\n",
            "Precisión: 0.7953091684434968\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1033\n",
            "           1       0.65      0.51      0.57       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.74      0.70      0.72      1407\n",
            "weighted avg       0.78      0.80      0.79      1407\n",
            "\n",
            "[[928 105]\n",
            " [183 191]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De nuevo los resultados anteriores muestran una precisión y un recall muy bajo."
      ],
      "metadata": {
        "id": "a7HwzyMrx6fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost\n",
        "pip install lightgbm\n",
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2c2yZiyfZ0M",
        "outputId": "c89c698f-d61e-4a04-c6c8-50450ba05ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repitamos el ejercicio con modelos mejor adaptados para clases desbalanceadas.\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "poUQIYXCgCSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'XGBoost': XGBClassifier(use_label_encoders=False, eval_metric='logloss', random_state=42),\n",
        "    'LightGBM': LGBMClassifier(random_state=42),\n",
        "    'CatBoost': CatBoostClassifier(verbose=0, random_seed=42)\n",
        "}"
      ],
      "metadata": {
        "id": "HO3uT8SOaq7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelTrainer(models, X_train, y_train, X_test, y_test, 5).train_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khp_bjbya6Z7",
        "outputId": "7581d542-e192-4eb4-88bf-44e609b0eb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo: XGBoost\n",
            "Precisión: 0.775408670931059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      1033\n",
            "           1       0.59      0.51      0.54       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.77      1407\n",
            "\n",
            "[[902 131]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
            "[LightGBM] [Info] Start training from score -1.016151\n",
            "Modelo: LightGBM\n",
            "Precisión: 0.7853589196872779\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1033\n",
            "           1       0.62      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.72      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "[[916 117]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "Modelo: CatBoost\n",
            "Precisión: 0.7953091684434968\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.87      1033\n",
            "           1       0.65      0.50      0.56       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.74      0.70      0.72      1407\n",
            "weighted avg       0.78      0.80      0.79      1407\n",
            "\n",
            "[[932 101]\n",
            " [187 187]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for comp in components:\n",
        "  print(f'Componentes: {comp}')\n",
        "  ModelTrainer(models, X_train, y_train, X_test, y_test, comp).train_models()\n",
        "  print('-' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJihIDsLgSpK",
        "outputId": "47ba50a9-5600-4ab0-91e2-4a50c778881b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Componentes: 3\n",
            "Modelo: XGBoost\n",
            "Precisión: 0.7647476901208244\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84      1033\n",
            "           1       0.57      0.48      0.52       374\n",
            "\n",
            "    accuracy                           0.76      1407\n",
            "   macro avg       0.69      0.67      0.68      1407\n",
            "weighted avg       0.75      0.76      0.76      1407\n",
            "\n",
            "[[896 137]\n",
            " [194 180]]\n",
            "--------------------------------------------------\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 765\n",
            "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
            "[LightGBM] [Info] Start training from score -1.016151\n",
            "Modelo: LightGBM\n",
            "Precisión: 0.7796730632551528\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      1033\n",
            "           1       0.60      0.50      0.55       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.72      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.77      1407\n",
            "\n",
            "[[910 123]\n",
            " [187 187]]\n",
            "--------------------------------------------------\n",
            "Modelo: CatBoost\n",
            "Precisión: 0.7825159914712153\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1033\n",
            "           1       0.62      0.48      0.54       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.72      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.77      1407\n",
            "\n",
            "[[920 113]\n",
            " [193 181]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Componentes: 5\n",
            "Modelo: XGBoost\n",
            "Precisión: 0.775408670931059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      1033\n",
            "           1       0.59      0.51      0.54       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.77      1407\n",
            "\n",
            "[[902 131]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1275\n",
            "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
            "[LightGBM] [Info] Start training from score -1.016151\n",
            "Modelo: LightGBM\n",
            "Precisión: 0.7853589196872779\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1033\n",
            "           1       0.62      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.72      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "[[916 117]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "Modelo: CatBoost\n",
            "Precisión: 0.7953091684434968\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.87      1033\n",
            "           1       0.65      0.50      0.56       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.74      0.70      0.72      1407\n",
            "weighted avg       0.78      0.80      0.79      1407\n",
            "\n",
            "[[932 101]\n",
            " [187 187]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Componentes: 7\n",
            "Modelo: XGBoost\n",
            "Precisión: 0.7768301350390903\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      1033\n",
            "           1       0.59      0.51      0.55       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.77      1407\n",
            "\n",
            "[[904 129]\n",
            " [185 189]]\n",
            "--------------------------------------------------\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
            "[LightGBM] [Info] Start training from score -1.016151\n",
            "Modelo: LightGBM\n",
            "Precisión: 0.7867803837953091\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86      1033\n",
            "           1       0.62      0.52      0.57       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "[[912 121]\n",
            " [179 195]]\n",
            "--------------------------------------------------\n",
            "Modelo: CatBoost\n",
            "Precisión: 0.7846481876332623\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86      1033\n",
            "           1       0.61      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.72      0.70      0.71      1407\n",
            "weighted avg       0.77      0.78      0.78      1407\n",
            "\n",
            "[[914 119]\n",
            " [184 190]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Componentes: 12\n",
            "Modelo: XGBoost\n",
            "Precisión: 0.775408670931059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      1033\n",
            "           1       0.59      0.51      0.55       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.77      1407\n",
            "\n",
            "[[899 134]\n",
            " [182 192]]\n",
            "--------------------------------------------------\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3060\n",
            "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
            "[LightGBM] [Info] Start training from score -1.016151\n",
            "Modelo: LightGBM\n",
            "Precisión: 0.7846481876332623\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86      1033\n",
            "           1       0.61      0.52      0.56       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.72      0.70      0.71      1407\n",
            "weighted avg       0.78      0.78      0.78      1407\n",
            "\n",
            "[[910 123]\n",
            " [180 194]]\n",
            "--------------------------------------------------\n",
            "Modelo: CatBoost\n",
            "Precisión: 0.7839374555792467\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1033\n",
            "           1       0.62      0.49      0.55       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.72      0.69      0.70      1407\n",
            "weighted avg       0.77      0.78      0.78      1407\n",
            "\n",
            "[[919 114]\n",
            " [190 184]]\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a repetir el proceso, pero ahora haciendo búsqueda más intensiva de hiperparámetros con GridSearch y validación cruzada."
      ],
      "metadata": {
        "id": "51KzibunyQs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grids = {\n",
        "    \"XGBoost\": {\n",
        "        'n_estimators': [200, 400],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'subsample': [0.8, 1.0],\n",
        "        'colsample_bytree': [0.8, 1.0],\n",
        "        'scale_pos_weight': [2.76]\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        'n_estimators': [200, 400],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'num_leaves': [15, 31, 63],\n",
        "        'subsample': [0.8, 1.0],\n",
        "        'scale_pos_weight': [None, 2.76]\n",
        "    },\n",
        "    \"CatBoost\": {\n",
        "        'iterations': [200, 400],\n",
        "        'depth': [4, 6, 8],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'l2_leaf_reg': [1, 3, 5],\n",
        "        'bagging_temperature': [0, 0.5, 1],\n",
        "        'class_weights': [[1, 2.76]]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "c6uhk5bAPFHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = {}\n",
        "for name, model in models.items():\n",
        "  print(f'Modelo: {name}')\n",
        "\n",
        "  grid_search = GridSearchCV(\n",
        "      estimator=model,\n",
        "      param_grid=param_grids[name],\n",
        "      cv=5,\n",
        "      n_jobs=-1,\n",
        "      verbose=2\n",
        "  )\n",
        "\n",
        "  grid_search.fit(X_train, y_train)\n",
        "\n",
        "  best_models[name] = grid_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icYgzf20PM1N",
        "outputId": "e4151c1e-250e-40cb-a7a8-fe9bac8a6866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo: XGBoost\n",
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "Modelo: LightGBM\n",
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 550\n",
            "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
            "[LightGBM] [Info] Start training from score -1.016151\n",
            "Modelo: CatBoost\n",
            "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontramos los mejores modelos.\n",
        "\n",
        "print(\"\\n Resultados finales:\\n\")\n",
        "for name, model in best_models.items():\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(classification_report(y_test, preds))\n",
        "    print(f\"{name}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx12jDIpQjf6",
        "outputId": "16aeec15-2a3e-471d-d57e-43a6bca7c699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Resultados finales:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81      1033\n",
            "           1       0.52      0.71      0.60       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.70      0.74      0.71      1407\n",
            "weighted avg       0.78      0.75      0.76      1407\n",
            "\n",
            "XGBoost: 0.7463\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      1033\n",
            "           1       0.63      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "LightGBM: 0.7903\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.76      0.82      1033\n",
            "           1       0.53      0.73      0.61       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.71      0.75      0.71      1407\n",
            "weighted avg       0.79      0.75      0.76      1407\n",
            "\n",
            "CatBoost: 0.7527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost es el que presenta mejor rendimiento, por lo cual intentaremos optimizarlo más con optuna."
      ],
      "metadata": {
        "id": "qUnK_KuFywnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJNn8gWziIbD",
        "outputId": "4bfceb60-6d21-4ed6-c56b-80277157e37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "def objective(trial):\n",
        "    # Definir el espacio de búsqueda\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 200, 800),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'class_weights': [1, 2.76],\n",
        "        'random_strength': trial.suggest_float('random_strength', 0, 2),\n",
        "        'verbose': 0\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Evaluamos con validación cruzada\n",
        "    score = cross_val_score(\n",
        "        model, X_train, y_train,\n",
        "        scoring=make_scorer(f1_score),\n",
        "        cv=3,\n",
        "        n_jobs=-1\n",
        "    ).mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "# Crear y ejecutar el estudio\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Mejores parámetros:\")\n",
        "print(study.best_params)\n",
        "print(\"Mejor F1:\", study.best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOJSZJjPMsgV",
        "outputId": "d244c627-016e-4d9f-af68-dfb60df7c721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-05 01:02:09,742] A new study created in memory with name: no-name-6f4590d6-2a1a-436d-95f6-666692d6be0a\n",
            "[I 2025-11-05 01:02:51,811] Trial 0 finished with value: 0.6256717709564651 and parameters: {'iterations': 342, 'depth': 10, 'learning_rate': 0.013821487217027572, 'l2_leaf_reg': 7.676607642828506, 'bagging_temperature': 0.5234666616824045, 'border_count': 131, 'random_strength': 1.9996877413789191}. Best is trial 0 with value: 0.6256717709564651.\n",
            "[I 2025-11-05 01:03:24,657] Trial 1 finished with value: 0.621483454939223 and parameters: {'iterations': 781, 'depth': 9, 'learning_rate': 0.015319579043164751, 'l2_leaf_reg': 4.567529624042563, 'bagging_temperature': 0.2802029426159457, 'border_count': 66, 'random_strength': 0.716323724133245}. Best is trial 0 with value: 0.6256717709564651.\n",
            "[I 2025-11-05 01:03:32,654] Trial 2 finished with value: 0.621364849401873 and parameters: {'iterations': 404, 'depth': 7, 'learning_rate': 0.023118018681818255, 'l2_leaf_reg': 8.56205905048457, 'bagging_temperature': 0.08252275642317264, 'border_count': 144, 'random_strength': 0.34692132468740033}. Best is trial 0 with value: 0.6256717709564651.\n",
            "[I 2025-11-05 01:03:39,124] Trial 3 finished with value: 0.6271670726239157 and parameters: {'iterations': 257, 'depth': 8, 'learning_rate': 0.015483441845937473, 'l2_leaf_reg': 5.951528591101525, 'bagging_temperature': 0.056302818859403025, 'border_count': 235, 'random_strength': 0.9855565590920579}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:03:59,835] Trial 4 finished with value: 0.6175879410390329 and parameters: {'iterations': 779, 'depth': 8, 'learning_rate': 0.0149169319955123, 'l2_leaf_reg': 8.095802301061148, 'bagging_temperature': 0.3926273612140442, 'border_count': 73, 'random_strength': 0.6104464245246382}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:04:10,783] Trial 5 finished with value: 0.6181855108006116 and parameters: {'iterations': 262, 'depth': 9, 'learning_rate': 0.037385625480340696, 'l2_leaf_reg': 6.433760924029059, 'bagging_temperature': 0.743278272809637, 'border_count': 90, 'random_strength': 0.5287789117702768}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:04:18,483] Trial 6 finished with value: 0.6267869741721915 and parameters: {'iterations': 232, 'depth': 9, 'learning_rate': 0.01847989443095283, 'l2_leaf_reg': 5.322229123978255, 'bagging_temperature': 0.8580612242051345, 'border_count': 70, 'random_strength': 1.8313731473653225}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:04:40,077] Trial 7 finished with value: 0.5716572516270073 and parameters: {'iterations': 481, 'depth': 9, 'learning_rate': 0.08622581570829013, 'l2_leaf_reg': 2.7938564538765833, 'bagging_temperature': 0.7455070094758294, 'border_count': 62, 'random_strength': 0.19583636215444367}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:04:53,926] Trial 8 finished with value: 0.5954139726640909 and parameters: {'iterations': 795, 'depth': 7, 'learning_rate': 0.048108400524593566, 'l2_leaf_reg': 5.169408464459119, 'bagging_temperature': 0.6651467717903227, 'border_count': 46, 'random_strength': 1.2846213421457935}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:05:34,187] Trial 9 finished with value: 0.6050683354979456 and parameters: {'iterations': 480, 'depth': 10, 'learning_rate': 0.03962057763917244, 'l2_leaf_reg': 4.590219227894112, 'bagging_temperature': 0.3128003067808942, 'border_count': 236, 'random_strength': 0.795485841938455}. Best is trial 3 with value: 0.6271670726239157.\n",
            "[I 2025-11-05 01:05:40,252] Trial 10 finished with value: 0.634296438929799 and parameters: {'iterations': 640, 'depth': 5, 'learning_rate': 0.011275269894812423, 'l2_leaf_reg': 1.8835684562786517, 'bagging_temperature': 0.01072870159404743, 'border_count': 251, 'random_strength': 1.2867974201617574}. Best is trial 10 with value: 0.634296438929799.\n",
            "[I 2025-11-05 01:05:44,709] Trial 11 finished with value: 0.6316446370867808 and parameters: {'iterations': 631, 'depth': 4, 'learning_rate': 0.010070633350358545, 'l2_leaf_reg': 1.4106409957814954, 'bagging_temperature': 0.04670925519426438, 'border_count': 255, 'random_strength': 1.2974421666602434}. Best is trial 10 with value: 0.634296438929799.\n",
            "[I 2025-11-05 01:05:50,880] Trial 12 finished with value: 0.632384453767948 and parameters: {'iterations': 634, 'depth': 4, 'learning_rate': 0.010583801814480672, 'l2_leaf_reg': 1.1567270793694906, 'bagging_temperature': 0.014496987329528532, 'border_count': 196, 'random_strength': 1.4083551671359897}. Best is trial 10 with value: 0.634296438929799.\n",
            "[I 2025-11-05 01:05:55,478] Trial 13 finished with value: 0.6346710751054113 and parameters: {'iterations': 650, 'depth': 4, 'learning_rate': 0.010206740099265029, 'l2_leaf_reg': 1.0387353694415982, 'bagging_temperature': 0.1999101865741349, 'border_count': 197, 'random_strength': 1.4700246286692917}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:03,040] Trial 14 finished with value: 0.624324674610615 and parameters: {'iterations': 638, 'depth': 5, 'learning_rate': 0.026211394931047176, 'l2_leaf_reg': 2.8363902799473495, 'bagging_temperature': 0.18402825363449865, 'border_count': 193, 'random_strength': 1.6473644710147346}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:07,833] Trial 15 finished with value: 0.6336590333922757 and parameters: {'iterations': 569, 'depth': 5, 'learning_rate': 0.010431143457130289, 'l2_leaf_reg': 2.7539214028464354, 'bagging_temperature': 0.19136714061187254, 'border_count': 194, 'random_strength': 1.559584007039939}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:15,641] Trial 16 finished with value: 0.6031331479739259 and parameters: {'iterations': 697, 'depth': 5, 'learning_rate': 0.0709256287538308, 'l2_leaf_reg': 1.7992792901350545, 'bagging_temperature': 0.4758201195937155, 'border_count': 166, 'random_strength': 1.1194777158984468}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:23,165] Trial 17 finished with value: 0.6259060080537178 and parameters: {'iterations': 551, 'depth': 6, 'learning_rate': 0.021095034347012997, 'l2_leaf_reg': 9.64391355963906, 'bagging_temperature': 0.17823778745287838, 'border_count': 223, 'random_strength': 0.9936907870990266}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:33,185] Trial 18 finished with value: 0.6191021883707711 and parameters: {'iterations': 715, 'depth': 6, 'learning_rate': 0.029742167621369244, 'l2_leaf_reg': 3.66903387938253, 'bagging_temperature': 0.29662481162362464, 'border_count': 217, 'random_strength': 1.514508788017272}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:37,229] Trial 19 finished with value: 0.6340738218567695 and parameters: {'iterations': 559, 'depth': 4, 'learning_rate': 0.012917112221771542, 'l2_leaf_reg': 2.263021420478445, 'bagging_temperature': 0.14326692264057625, 'border_count': 253, 'random_strength': 1.8158043977850984}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:46,609] Trial 20 finished with value: 0.6257344248003067 and parameters: {'iterations': 703, 'depth': 6, 'learning_rate': 0.018812959261067953, 'l2_leaf_reg': 3.4655414295817333, 'bagging_temperature': 0.972653829069865, 'border_count': 166, 'random_strength': 1.1718533656237125}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:50,653] Trial 21 finished with value: 0.6337110172047655 and parameters: {'iterations': 569, 'depth': 4, 'learning_rate': 0.012505165429524352, 'l2_leaf_reg': 2.0493244756577447, 'bagging_temperature': 0.1440990463362759, 'border_count': 251, 'random_strength': 1.7290200845907786}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:06:54,404] Trial 22 finished with value: 0.6337584222158253 and parameters: {'iterations': 521, 'depth': 4, 'learning_rate': 0.011523273755526359, 'l2_leaf_reg': 1.0036892638845514, 'bagging_temperature': 0.25159265375066275, 'border_count': 210, 'random_strength': 1.9439396363561268}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:07:00,116] Trial 23 finished with value: 0.6332654123617512 and parameters: {'iterations': 436, 'depth': 5, 'learning_rate': 0.013316093861022602, 'l2_leaf_reg': 2.011614408458005, 'bagging_temperature': 0.4069182860847427, 'border_count': 237, 'random_strength': 1.448476494238201}. Best is trial 13 with value: 0.6346710751054113.\n",
            "[I 2025-11-05 01:07:04,769] Trial 24 finished with value: 0.6350873664540756 and parameters: {'iterations': 606, 'depth': 4, 'learning_rate': 0.01695685037110959, 'l2_leaf_reg': 3.694948746380949, 'bagging_temperature': 0.09401663546467037, 'border_count': 179, 'random_strength': 1.7851931210401664}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:12,137] Trial 25 finished with value: 0.6311815077509833 and parameters: {'iterations': 613, 'depth': 5, 'learning_rate': 0.01746323069593585, 'l2_leaf_reg': 3.677036159273444, 'bagging_temperature': 0.003196060226678314, 'border_count': 170, 'random_strength': 1.5984931140816439}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:19,639] Trial 26 finished with value: 0.6205552097900844 and parameters: {'iterations': 685, 'depth': 6, 'learning_rate': 0.022854680079213076, 'l2_leaf_reg': 4.219624631455703, 'bagging_temperature': 0.08525503277148704, 'border_count': 125, 'random_strength': 1.2897259396854037}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:26,482] Trial 27 finished with value: 0.6341563314667312 and parameters: {'iterations': 743, 'depth': 4, 'learning_rate': 0.011862110216365221, 'l2_leaf_reg': 2.6758637340807194, 'bagging_temperature': 0.235823559855385, 'border_count': 185, 'random_strength': 1.7188742159391917}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:32,076] Trial 28 finished with value: 0.6286930741879514 and parameters: {'iterations': 665, 'depth': 5, 'learning_rate': 0.017165396245988982, 'l2_leaf_reg': 1.656681453684639, 'bagging_temperature': 0.10721260180163045, 'border_count': 110, 'random_strength': 0.9034093609822209}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:37,375] Trial 29 finished with value: 0.63391563640176 and parameters: {'iterations': 598, 'depth': 4, 'learning_rate': 0.013640929445799806, 'l2_leaf_reg': 3.3322943740728146, 'bagging_temperature': 0.5721690001042514, 'border_count': 145, 'random_strength': 1.9780709597189747}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:41,394] Trial 30 finished with value: 0.6238211642208132 and parameters: {'iterations': 353, 'depth': 5, 'learning_rate': 0.05909005747622285, 'l2_leaf_reg': 6.789099519827662, 'bagging_temperature': 0.3850256890488942, 'border_count': 205, 'random_strength': 1.1302792621975346}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:46,689] Trial 31 finished with value: 0.6332266487898658 and parameters: {'iterations': 732, 'depth': 4, 'learning_rate': 0.011642561656273937, 'l2_leaf_reg': 2.412474756133522, 'bagging_temperature': 0.2081840424059208, 'border_count': 179, 'random_strength': 1.7332065490947326}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:53,601] Trial 32 finished with value: 0.6341987609716934 and parameters: {'iterations': 664, 'depth': 4, 'learning_rate': 0.014689501866518824, 'l2_leaf_reg': 2.9597551542733647, 'bagging_temperature': 0.2535813472316455, 'border_count': 153, 'random_strength': 1.3843391686755635}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:07:58,360] Trial 33 finished with value: 0.6330628416975808 and parameters: {'iterations': 658, 'depth': 4, 'learning_rate': 0.015815670005414065, 'l2_leaf_reg': 4.2945313593284276, 'bagging_temperature': 0.11508420762363211, 'border_count': 153, 'random_strength': 1.4174496665421528}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:04,409] Trial 34 finished with value: 0.6321218175079323 and parameters: {'iterations': 587, 'depth': 5, 'learning_rate': 0.014405403907186896, 'l2_leaf_reg': 3.172442032545928, 'bagging_temperature': 0.35728818446733074, 'border_count': 131, 'random_strength': 1.3280395388648065}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:11,397] Trial 35 finished with value: 0.6271358509788943 and parameters: {'iterations': 517, 'depth': 6, 'learning_rate': 0.02006354960901196, 'l2_leaf_reg': 1.49824797855353, 'bagging_temperature': 0.4786736121620622, 'border_count': 152, 'random_strength': 1.1910194369198235}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:16,475] Trial 36 finished with value: 0.6343740367788905 and parameters: {'iterations': 747, 'depth': 4, 'learning_rate': 0.015930770726842184, 'l2_leaf_reg': 3.9449854266385698, 'bagging_temperature': 0.04688152786766503, 'border_count': 123, 'random_strength': 1.5296069152753609}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:29,487] Trial 37 finished with value: 0.6203674758884681 and parameters: {'iterations': 741, 'depth': 7, 'learning_rate': 0.02707461906954777, 'l2_leaf_reg': 5.950401429751404, 'bagging_temperature': 0.053633635699864235, 'border_count': 109, 'random_strength': 1.9026476024153933}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:37,513] Trial 38 finished with value: 0.6270768411150177 and parameters: {'iterations': 770, 'depth': 5, 'learning_rate': 0.016617200755376153, 'l2_leaf_reg': 4.761237906416177, 'bagging_temperature': 0.005371771338063366, 'border_count': 128, 'random_strength': 0.0132884145363098}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:56,162] Trial 39 finished with value: 0.6148415456725821 and parameters: {'iterations': 765, 'depth': 8, 'learning_rate': 0.023431706209891927, 'l2_leaf_reg': 4.038246580953536, 'bagging_temperature': 0.07812664439537745, 'border_count': 99, 'random_strength': 1.4828848946825952}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:08:59,488] Trial 40 finished with value: 0.6331685285876546 and parameters: {'iterations': 448, 'depth': 4, 'learning_rate': 0.034568720336856366, 'l2_leaf_reg': 4.997815431581532, 'bagging_temperature': 0.1471660655670705, 'border_count': 230, 'random_strength': 1.630162215496809}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:09:05,682] Trial 41 finished with value: 0.6338332794565311 and parameters: {'iterations': 687, 'depth': 4, 'learning_rate': 0.014580181734237016, 'l2_leaf_reg': 3.0792645739845104, 'bagging_temperature': 0.26670437817623804, 'border_count': 139, 'random_strength': 1.4028349798203243}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:09:10,624] Trial 42 finished with value: 0.6317054279739046 and parameters: {'iterations': 670, 'depth': 4, 'learning_rate': 0.01004722903780368, 'l2_leaf_reg': 3.7916291570641367, 'bagging_temperature': 0.057650400869810554, 'border_count': 161, 'random_strength': 1.546602838719743}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:09:15,995] Trial 43 finished with value: 0.6341545954727954 and parameters: {'iterations': 610, 'depth': 4, 'learning_rate': 0.015161456616387636, 'l2_leaf_reg': 2.484888318094629, 'bagging_temperature': 0.3338986635897271, 'border_count': 179, 'random_strength': 1.813018380886693}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:09:22,364] Trial 44 finished with value: 0.6337065054482116 and parameters: {'iterations': 652, 'depth': 5, 'learning_rate': 0.011667894020224051, 'l2_leaf_reg': 1.3935156310761792, 'bagging_temperature': 0.12295014937067843, 'border_count': 117, 'random_strength': 1.3469996811559375}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:09:27,367] Trial 45 finished with value: 0.6340416162108714 and parameters: {'iterations': 718, 'depth': 4, 'learning_rate': 0.01392788890173567, 'l2_leaf_reg': 1.9140351309975783, 'bagging_temperature': 0.20864848449693935, 'border_count': 80, 'random_strength': 1.2369830676078182}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:09:33,671] Trial 46 finished with value: 0.6298038173634679 and parameters: {'iterations': 626, 'depth': 4, 'learning_rate': 0.019594958741075592, 'l2_leaf_reg': 5.891390186291308, 'bagging_temperature': 0.0415340324598068, 'border_count': 201, 'random_strength': 1.6761705097021171}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:10:30,432] Trial 47 finished with value: 0.6149362003212716 and parameters: {'iterations': 789, 'depth': 10, 'learning_rate': 0.010882131530456257, 'l2_leaf_reg': 3.03994514985556, 'bagging_temperature': 0.09124354463020103, 'border_count': 155, 'random_strength': 1.0668127760530854}. Best is trial 24 with value: 0.6350873664540756.\n",
            "[I 2025-11-05 01:10:34,876] Trial 48 finished with value: 0.6358130374717383 and parameters: {'iterations': 543, 'depth': 5, 'learning_rate': 0.012629950316874172, 'l2_leaf_reg': 7.417537467606664, 'bagging_temperature': 0.58685530200088, 'border_count': 140, 'random_strength': 0.9019333926811216}. Best is trial 48 with value: 0.6358130374717383.\n",
            "[I 2025-11-05 01:10:40,614] Trial 49 finished with value: 0.6333885715168489 and parameters: {'iterations': 493, 'depth': 5, 'learning_rate': 0.012583244905878307, 'l2_leaf_reg': 7.451793043917382, 'bagging_temperature': 0.619413217814333, 'border_count': 140, 'random_strength': 0.6178315869686635}. Best is trial 48 with value: 0.6358130374717383.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros:\n",
            "{'iterations': 543, 'depth': 5, 'learning_rate': 0.012629950316874172, 'l2_leaf_reg': 7.417537467606664, 'bagging_temperature': 0.58685530200088, 'border_count': 140, 'random_strength': 0.9019333926811216}\n",
            "Mejor F1: 0.6358130374717383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_optimization_history(study)\n",
        "optuna.visualization.plot_param_importances(study)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "axa4ZIT8kZoM",
        "outputId": "4166c329-03d2-44be-98d4-9c51f22b0722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"da3382c7-5cf8-4b37-96c0-373acbe1909d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da3382c7-5cf8-4b37-96c0-373acbe1909d\")) {                    Plotly.newPlot(                        \"da3382c7-5cf8-4b37-96c0-373acbe1909d\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"iterations (IntDistribution): 0.011949732552433503\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"random_strength (FloatDistribution): 0.02668623267499272\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"l2_leaf_reg (FloatDistribution): 0.04696633060738396\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"bagging_temperature (FloatDistribution): 0.06781193649867905\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"depth (IntDistribution): 0.08453211697937925\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"border_count (IntDistribution): 0.17215363071240852\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.5899000199747231\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.01\",\"0.03\",\"0.05\",\"0.07\",\"0.08\",\"0.17\",\"0.59\"],\"textposition\":\"outside\",\"x\":[0.011949732552433503,0.02668623267499272,0.04696633060738396,0.06781193649867905,0.08453211697937925,0.17215363071240852,0.5899000199747231],\"y\":[\"iterations\",\"random_strength\",\"l2_leaf_reg\",\"bagging_temperature\",\"depth\",\"border_count\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('da3382c7-5cf8-4b37-96c0-373acbe1909d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mejor F1-score:\", study.best_value)\n",
        "print(\"Mejores parámetros:\")\n",
        "for k, v in study.best_params.items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HH1aFk7kqsm",
        "outputId": "08fcebd1-bfcf-45c4-da3f-ce6949418216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏆 Mejor F1-score: 0.6358130374717383\n",
            "🧩 Mejores parámetros:\n",
            "  iterations: 543\n",
            "  depth: 5\n",
            "  learning_rate: 0.012629950316874172\n",
            "  l2_leaf_reg: 7.417537467606664\n",
            "  bagging_temperature: 0.58685530200088\n",
            "  border_count: 140\n",
            "  random_strength: 0.9019333926811216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustamos de nuevo el modelo con los parámetros encontrados por optuna."
      ],
      "metadata": {
        "id": "30SvHSvHy_kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "best_model = CatBoostClassifier(**best_params)\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OdrGSxtIkzuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test > )\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ozREW4ylAiB",
        "outputId": "e716ef23-67ff-4bff-970a-516dd73d9a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1033\n",
            "           1       0.66      0.52      0.58       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.75      0.71      0.73      1407\n",
            "weighted avg       0.79      0.80      0.79      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_adj = (y_pred > 0.8).astype(int)\n",
        "print(classification_report(y_test, y_pred_adj))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seoX6PXmmhPJ",
        "outputId": "e78fe5bb-c729-4885-e3b8-35b4b1a58082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1033\n",
            "           1       0.66      0.52      0.58       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.75      0.71      0.73      1407\n",
            "weighted avg       0.79      0.80      0.79      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred_adj))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68J4rYTTnA1Z",
        "outputId": "473be37a-2472-48c2-bf26-85ef19930068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[933 100]\n",
            " [179 195]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de rendimiento de modelos:\n",
        "\n",
        "- De acuerdo con los Score, el mejor modelo fué CatBoost. sin embargo, la precisción del modelo y recall continuan siendo bastante bajos. Esto debe deberse en mayor efecto por el desbalance drástico de las clases.  y/o por que puede ser que las variables de entrada no sean los suficientemente representativas de la variable de salida.\n",
        "\n",
        "- Otras alternativas a explorar pueden ser redes neuronales, sin embargo el conjunto de datos tampoco parece ser lo suficientemente grande para lograr este objetivo. sin embargo para este ejercicio, optaremos por quedarnos con CatBoost con los mejores resultados.\n"
      ],
      "metadata": {
        "id": "082KwbK3zGTe"
      }
    }
  ]
}